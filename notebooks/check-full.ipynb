{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/NVME1TB/Projects/kaggle-severstal-2019\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES = '/home/denilv/Projects/kaggle-severstal-2019/data/train_images/'\n",
    "VALID_CLS_CSV = '/mnt/NVME1TB/Projects/kaggle-severstal-2019/data/cls_df/valid.csv'\n",
    "VALID_SEGM_CSV = '/mnt/NVME1TB/Projects/kaggle-severstal-2019/data/segm_df/valid.csv'\n",
    "TEST_IMAGES = '/home/denilv/Projects/kaggle-severstal-2019/data/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "CUDA_VISIBLE_DEVICES = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyarrow not available, switching to pickle. To install pyarrow, run `pip install pyarrow`.\n",
      "lz4 not available, disabling compression. To install lz4, run `pip install lz4`.\n",
      "wandb not available, to install wandb, run `pip install wandb`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = CUDA_VISIBLE_DEVICES\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp\n",
    "import cv2\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from modules.comp_tools import (\n",
    "    Dataset,\n",
    "    ClsDataset,\n",
    "    AUGMENTATIONS_TRAIN, \n",
    "    get_segm_model,\n",
    "    get_model,\n",
    "    ModelAgg, \n",
    "    predict_semg, \n",
    "    decode_masks, \n",
    "    dice_channel_torch,\n",
    "    predict_cls,\n",
    "    preprocessing_fn,\n",
    "    to_tensor,\n",
    "    decode_masks,\n",
    "    TestDataset,\n",
    "    TestClsDataset,\n",
    "    mask2rle,\n",
    ")\n",
    "from torch.utils.data import DataLoader as BaseDataLoader\n",
    "\n",
    "import ttach as tta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_df = pd.read_csv(VALID_CLS_CSV, index_col='ImageId')\n",
    "segm_df = pd.read_csv(VALID_SEGM_CSV, index_col='ImageId').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids = cls_df.index[cls_df.has_defect == 0].values.tolist()\n",
    "not_empty_ids = cls_df.index[cls_df.has_defect == 1].values.tolist()\n",
    "inter_ids = (cls_df.index & segm_df.index).unique().values.tolist()\n",
    "\n",
    "ids = empty_ids + inter_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv').fillna('')\n",
    "df = df.join(df.ImageId_ClassId.str.split('_', expand=True).rename(columns={0: 'ImageId', 1: 'ClassId'}))\n",
    "df.set_index('ImageId', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2f67b763114844b1523f58e6efd87e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5884), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cls_df = cls_df.loc[ids]\n",
    "segm_df = df.loc[ids]\n",
    "segm_df = decode_masks(segm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: list(map(int, x.strip('[]').split()))\n",
    "cls_df['defect_map'] = cls_df.defect_map.apply(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_dl = BaseDataLoader(\n",
    "    ClsDataset(\n",
    "        cls_df.reset_index(),\n",
    "        img_prefix=TRAIN_IMAGES, \n",
    "        augmentations=None, \n",
    "        preprocess_img=preprocessing_fn,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "segm_dl = BaseDataLoader(\n",
    "    Dataset(\n",
    "        segm_df.reset_index(),\n",
    "        img_prefix=TRAIN_IMAGES, \n",
    "        augmentations=None, \n",
    "        preprocess_img=preprocessing_fn,\n",
    "        preprocess_mask=to_tensor,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check segm models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.jit import load\n",
    "\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_models.append(load('data/blend_models/segm/unet_se_resnext50_32x4d.pth').cuda().eval())\n",
    "segm_models.append(load('data/blend_models/segm/unet_mobilenet2.pth').cuda().eval())\n",
    "segm_models.append(load('data/blend_models/segm/unet_resnet34.pth').cuda().eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading logs/fpn_se_resnext101_32x4d_softmax_withEmpty/checkpoints/best.pth\n",
      "<All keys matched successfully>\n",
      "Loading logs/unet_resnet18_softmax_withEmpty/checkpoints/best.pth\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# ####\n",
    "# arch_args = dict(\n",
    "#     encoder_name='se_resnext101_32x4d',\n",
    "#     encoder_weights='imagenet',\n",
    "#     classes=4, \n",
    "#     activation='sigmoid',\n",
    "# )\n",
    "# load_weights = 'logs/fpn_se_resnext101_32x4d/checkpoints/best.pth'\n",
    "# model = get_segm_model('FPN', arch_args, load_weights=load_weights)\n",
    "# model = model.cuda()\n",
    "# model = model.eval()\n",
    "# segm_models.append(model)\n",
    "\n",
    "####\n",
    "arch_args = dict(\n",
    "    encoder_name='se_resnext101_32x4d',\n",
    "    encoder_weights='imagenet',\n",
    "    classes=4, \n",
    "    activation='sigmoid',\n",
    ")\n",
    "load_weights = 'logs/fpn_se_resnext101_32x4d_softmax_withEmpty/checkpoints/best.pth'\n",
    "model = get_segm_model('FPN', arch_args, load_weights=load_weights)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n",
    "segm_models.append(model)\n",
    "\n",
    "####\n",
    "arch_args = dict(\n",
    "    encoder_name='resnet18',\n",
    "    encoder_weights='imagenet',\n",
    "    classes=4, \n",
    "    activation='softmax',\n",
    ")\n",
    "load_weights = 'logs/unet_resnet18_softmax_withEmpty/checkpoints/best.pth'\n",
    "model = get_segm_model('Unet', arch_args, load_weights=load_weights)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n",
    "segm_models.append(model)\n",
    "\n",
    "# ####\n",
    "# arch_args = dict(\n",
    "#     encoder_name='resnet50',\n",
    "#     encoder_weights='imagenet',\n",
    "#     classes=4, \n",
    "#     activation='sigmoid',\n",
    "# )\n",
    "# load_weights = 'logs/fpn_resnet50/checkpoints/best.pth'\n",
    "# model = get_segm_model('FPN', arch_args, load_weights=load_weights)\n",
    "# model = model.cuda()\n",
    "# model = model.eval()\n",
    "# segm_models.append(model)\n",
    "\n",
    "# ####\n",
    "# arch_args = dict(\n",
    "#     encoder_name='resnet50',\n",
    "#     encoder_weights='imagenet',\n",
    "#     classes=4, \n",
    "#     activation='sigmoid',\n",
    "# )\n",
    "# load_weights = 'logs/unet_resnet50/checkpoints/best.pth'\n",
    "# model = get_segm_model('Unet', arch_args, load_weights=load_weights)\n",
    "# model = model.cuda()\n",
    "# model = model.eval()\n",
    "# segm_models.append(model)\n",
    "\n",
    "\n",
    "# ####\n",
    "# arch_args = dict(\n",
    "#     encoder_name='se_resnext50_32x4d',\n",
    "#     encoder_weights='imagenet',\n",
    "#     classes=4, \n",
    "#     activation='sigmoid',\n",
    "# )\n",
    "# load_weights = 'logs/unet_se_resnext50_32x4d/checkpoints/best.pth'\n",
    "# model = get_segm_model('Unet', arch_args, load_weights=load_weights)\n",
    "# model = model.cuda()\n",
    "# model = model.eval()\n",
    "# segm_models.append(model)\n",
    "\n",
    "# ####\n",
    "# arch_args = dict(\n",
    "#     encoder_name='se_resnext101_32x4d',\n",
    "#     encoder_weights='imagenet',\n",
    "#     classes=4, \n",
    "#     activation='sigmoid',\n",
    "#     attention_type='scse',\n",
    "# )\n",
    "# load_weights = 'logs/unet_se_resnext101_32x4d_attn/checkpoints/best.pth'\n",
    "# model = get_segm_model('Unet', arch_args, load_weights=load_weights)\n",
    "# model = model.cuda()\n",
    "# model = model.eval()\n",
    "# segm_models.append(model)\n",
    "\n",
    "\n",
    "# segm_model_ens = ModelAgg(segm_models)\n",
    "# segm_model = tta.SegmentationTTAWrapper(model, tta.aliases.hflip_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading logs/fpn_efficientnet-b5_crop/checkpoints/best_full.pth\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "arch_args = dict(\n",
    "    encoder_name='efficientnet-b5',\n",
    "    encoder_weights='imagenet',\n",
    "    classes=5, \n",
    "    activation='softmax',\n",
    ")\n",
    "load_weights = 'logs/fpn_efficientnet-b5_crop/checkpoints/best_full.pth'\n",
    "model = get_segm_model('FPN', arch_args, load_weights=load_weights)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n",
    "segm_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dfe87f4dab421b893cf2541e3adbe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5336), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "segm_df = pd.read_csv(VALID_SEGM_CSV, index_col='ImageId').fillna('')\n",
    "segm_df = decode_masks(segm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    segm_df.reset_index(),\n",
    "    img_prefix=TRAIN_IMAGES, \n",
    "    augmentations=None,\n",
    "    background=False,\n",
    "    preprocess_img=preprocessing_fn,\n",
    "    preprocess_mask=to_tensor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_dl = BaseDataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check slicer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_model = tta.SegmentationTTAWrapper(model, tta.aliases.hflip_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.comp_tools import CroppedDataset\n",
    "from pytorch_toolbelt.inference.tiles import ImageSlicer, CudaTileMerger\n",
    "from modules.common import visualize\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_toolbelt.utils.torch_utils import to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 0.5\n",
    "\n",
    "d = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(model, dataset, max_iters=100):\n",
    "    tiler = ImageSlicer((256, 1600), (256, 416), 256)\n",
    "    dice_scores = []\n",
    "    i = 0\n",
    "    for img, gt_mask in tqdm(dataset):\n",
    "        if i >= max_iters:\n",
    "            break\n",
    "        merger = CudaTileMerger(tiler.target_shape, 5, tiler.weight)\n",
    "        tiles = [preprocessing_fn(image_tile) for image_tile in tiler.split(img)]\n",
    "        dl = DataLoader(list(zip(tiles, tiler.crops)), batch_size=8, pin_memory=True)\n",
    "        for tiles_batch, coords_batch in dl:\n",
    "            with torch.no_grad():\n",
    "                tiles_batch = tiles_batch.float().cuda()\n",
    "                pred_batch = model(tiles_batch)\n",
    "                merger.integrate_batch(pred_batch, coords_batch)\n",
    "\n",
    "        merged_logits = merger.merge()\n",
    "        merged_probs = torch.sigmoid(merged_logits)\n",
    "        merged_probs = to_numpy(merged_probs).transpose(1, 2, 0)\n",
    "        pred_probs = tiler.crop_to_orignal_size(merged_probs)\n",
    "        pred_mask = (pred_probs > th).astype(np.uint8)\n",
    "\n",
    "        batch_pred_mask = np.expand_dims(pred_mask[..., :-1], 0)\n",
    "        batch_gt_mask = np.expand_dims(gt_mask[..., :-1], 0)\n",
    "        dice_score = dice_channel_torch(batch_pred_mask, batch_gt_mask)\n",
    "        dice_scores.append(dice_score)\n",
    "    #     print(np.round(dice_score, 3))\n",
    "    #     visualize(img=img, gt=gt_mask[..., :-1].sum(-1), pred=pred_mask[..., :-1].sum(-1))\n",
    "        i += 1\n",
    "    print(np.mean(dice_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_channel_torch(probability, truth):\n",
    "    batch_size = truth.shape[0]\n",
    "    channel_num = truth.shape[1]\n",
    "    mean_dice_channel = 0.\n",
    "    for i in range(batch_size):\n",
    "        for j in range(channel_num):\n",
    "            channel_dice = dice_single_channel(probability[i, j,:,:], truth[i, j, :, :])\n",
    "            mean_dice_channel += channel_dice / (batch_size * channel_num)\n",
    "    return mean_dice_channel\n",
    "\n",
    "def dice_single_channel(probability, truth, eps=1e-9):\n",
    "    p = probability.flatten()\n",
    "    t = (truth.flatten() > 0.5).astype(float)\n",
    "    dice = (2.0 * (p * t).sum() + eps)/ (p.sum() + t.sum() + eps)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_one(predict, min_size):\n",
    "    H,W = predict.shape\n",
    "    num_component, component = cv2.connectedComponents(predict.astype(np.uint8))\n",
    "    predict = np.zeros((H,W), np.bool)\n",
    "    for c in range(1,num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predict[p] = True\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(p, t=0.5):\n",
    "    if t != 0:\n",
    "        return p**t\n",
    "    else:\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ens = ModelAgg(segm_models)\n",
    "tta_se_resnext101 = tta.SegmentationTTAWrapper(segm_models[0], tta.aliases.hflip_transform())\n",
    "tta_resnet18 = tta.SegmentationTTAWrapper(segm_models[1], tta.aliases.hflip_transform())\n",
    "tta_model_ens = tta.SegmentationTTAWrapper(model_ens, tta.aliases.hflip_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ad233395ca49049254e1d6f69d46ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0 0.9127107775961745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71778bbb4ea423a8e567deebba70109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 0.9152353536871027\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26142d333fd14cf786dda6ea924fd7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 0.9107266681551741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa44e549b8094d37b15fcd518692fd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 0.9115327435686017\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "segm_th = 0.5\n",
    "\n",
    "dices = []\n",
    "cls_preds = []\n",
    "for i, segm_model in enumerate([model_ens, tta_se_resnext101, tta_resnet18, tta_model_ens]):\n",
    "    with torch.no_grad():\n",
    "        for segm_batch in tqdm(segm_dl, total=len(segm_dl)):\n",
    "            segm_features, segm_gt = segm_batch\n",
    "            segm_features = segm_features.to(device)\n",
    "            segm_logits = segm_model(segm_features).detach().cpu()\n",
    "            pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "            pred_masks = pred_masks.astype(np.uint8)\n",
    "#             for img_id in range(len(pred_masks)):\n",
    "#                 for j in range(4):\n",
    "#                     pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=200)\n",
    "            batch_dice = dice_channel_torch(pred_masks, segm_gt.numpy())\n",
    "            dices.append(batch_dice)\n",
    "    print(i, np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "0 0.9078998254167824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 0.9058301214405342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2 0.9044565133241284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=84), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 0.9057805123247601\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "segm_th = 0.5\n",
    "\n",
    "dices = []\n",
    "cls_preds = []\n",
    "for i, segm_model in enumerate([model_ens, tta_se_resnext101, tta_resnet18, tta_model_ens]):\n",
    "    with torch.no_grad():\n",
    "        for segm_batch in tqdm(segm_dl, total=len(segm_dl)):\n",
    "            segm_features, segm_gt = segm_batch\n",
    "            segm_features = segm_features.to(device)\n",
    "            segm_logits = segm_model(segm_features).detach().cpu()\n",
    "            pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "            pred_masks = pred_masks.astype(np.uint8)\n",
    "#             for img_id in range(len(pred_masks)):\n",
    "#                 for j in range(4):\n",
    "#                     pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=200)\n",
    "            batch_dice = dice_channel_torch(pred_masks, segm_gt.numpy())\n",
    "            dices.append(batch_dice)\n",
    "    print(i, np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_model = tta_model_ens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check cls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading logs/cls_resnet34_multiclass/checkpoints/best_non_augm.pth\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "cls_models = []\n",
    "\n",
    "# ####\n",
    "# ENCODER = 'resnet50'\n",
    "# ENCODER_WEIGHTS = 'imagenet'\n",
    "# ACTIVATION = 'sigmoid'\n",
    "\n",
    "# CONTINUE = 'logs/cls_resnet50/checkpoints/best_augm.pth'\n",
    "\n",
    "# model = get_model(ENCODER, 2, ENCODER_WEIGHTS, load_weights=CONTINUE)\n",
    "# model = model.cuda()\n",
    "# model = model.eval()\n",
    "# cls_models.append(model)\n",
    "\n",
    "# ####\n",
    "# ENCODER = 'resnet18'\n",
    "# ENCODER_WEIGHTS = 'imagenet'\n",
    "# ACTIVATION = 'sigmoid'\n",
    "\n",
    "# CONTINUE = 'logs/cls_resnet18/checkpoints/best_augm.pth'\n",
    "\n",
    "# model = get_model(ENCODER, 2, ENCODER_WEIGHTS, load_weights=CONTINUE)\n",
    "# model = model.cuda()\n",
    "# model = model.eval()\n",
    "# cls_models.append(model)\n",
    "\n",
    "####\n",
    "ENCODER = 'resnet34'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = 'softmax'\n",
    "\n",
    "CONTINUE = 'logs/cls_resnet34_multiclass/checkpoints/best_non_augm.pth'\n",
    "\n",
    "model = get_model(ENCODER, 5, ENCODER_WEIGHTS, load_weights=CONTINUE)\n",
    "model = model.cuda()\n",
    "model = model.eval()\n",
    "cls_models.append(model)\n",
    "\n",
    "\n",
    "cls_model_ens = ModelAgg(cls_models)\n",
    "cls_model_tta = tta.ClassificationTTAWrapper(model, tta.aliases.hflip_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: list(map(int, x.strip('[]').split()))\n",
    "df = pd.read_csv(VALID_CLS_CSV)\n",
    "df['defect_map'] = df.defect_map.apply(f)\n",
    "\n",
    "cls_dl = BaseDataLoader(\n",
    "    ClsDataset(\n",
    "        df,\n",
    "        img_prefix=TRAIN_IMAGES, \n",
    "        augmentations=None, #AUGMENTATIONS_TRAIN,\n",
    "        mode='multiclass',\n",
    "        binary=False,\n",
    "        preprocess_img=preprocessing_fn,\n",
    "    ), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4de188475247d4aa87f786a8ddaa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=157), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "cls_th = 0.5\n",
    "\n",
    "cls_probs = []\n",
    "cls_preds = []\n",
    "cls_gts = []\n",
    "with torch.no_grad():\n",
    "    for cls_batch in tqdm(cls_dl, total=len(cls_dl)):\n",
    "        cls_features, cls_gt = cls_batch['features'], cls_batch['targets_one_hot']\n",
    "        cls_features = cls_features.to(device)\n",
    "        cls_logits = cls_model(cls_features).detach().cpu()\n",
    "#         cls_prob = torch.softmax(cls_logits, 1)[:, 1].numpy()\n",
    "        cls_prob = torch.softmax(cls_logits, 1).numpy()\n",
    "        cls_pred = (cls_prob > cls_th).astype(int)\n",
    "        cls_preds.append(cls_pred)\n",
    "        cls_probs.append(cls_prob)\n",
    "        cls_gts.append(cls_gt.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = np.concatenate(cls_probs).argmax(axis=1)\n",
    "labels = np.vstack(cls_gts).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.8798966e-01, 7.0864409e-03, 7.1337220e-04, 4.1426835e-03,\n",
       "        6.7845722e-05]], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th 0.10 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.20 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.30 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.40 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.50 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.60 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.70 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.80 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 0.90 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n",
      "Th 1.00 Acc 0.936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       180\n",
      "           1       0.79      0.90      0.84        42\n",
      "           2       0.94      0.93      0.94      1008\n",
      "           3       0.71      0.72      0.71       103\n",
      "           4       0.97      0.97      0.97      1179\n",
      "\n",
      "    accuracy                           0.94      2512\n",
      "   macro avg       0.86      0.88      0.87      2512\n",
      "weighted avg       0.94      0.94      0.94      2512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for th in np.arange(0.1, 1.01, 0.1):\n",
    "    print(f'Th {th:0.2f} Acc {accuracy_score(labels, prob):0.3f}')\n",
    "    print(classification_report(labels, prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Th 0.10 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.20 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.30 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.40 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.50 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.60 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.70 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.80 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 0.90 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n",
      "Th 1.00 Acc 0.863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.67      0.59       180\n",
      "           1       0.62      0.12      0.20        42\n",
      "           2       0.88      0.91      0.89      1008\n",
      "           3       0.65      0.54      0.59       103\n",
      "           4       0.93      0.91      0.92      1179\n",
      "\n",
      "    accuracy                           0.86      2512\n",
      "   macro avg       0.72      0.63      0.64      2512\n",
      "weighted avg       0.87      0.86      0.86      2512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for th in np.arange(0.1, 1.01, 0.1):\n",
    "    print(f'Th {th:0.2f} Acc {accuracy_score(labels, prob):0.3f}')\n",
    "    print(classification_report(labels, prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_model = tta_se_resnext101\n",
    "cls_model = cls_model_tta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9774952063689157\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "cls_th = 0.5\n",
    "segm_th = 0.5\n",
    "\n",
    "dices = []\n",
    "cls_preds = []\n",
    "with torch.no_grad():\n",
    "    for cls_batch, segm_batch in tqdm(zip(cls_dl, segm_dl), total=len(cls_dl)):\n",
    "        cls_features, cls_gt = cls_batch['features'], cls_batch['targets']\n",
    "        cls_features = cls_features.to(device)\n",
    "        cls_logits = cls_model(cls_features).detach().cpu()\n",
    "        cls_probs = torch.softmax(cls_logits, 1).numpy()\n",
    "        cls_pred = cls_probs.argmax(axis=1) # (cls_probs > cls_th).astype(int)\n",
    "        cls_preds.append(cls_pred)\n",
    "        \n",
    "        segm_features, segm_gt = segm_batch\n",
    "        segm_features = segm_features.to(device)\n",
    "        segm_logits = segm_model(segm_features).detach().cpu()\n",
    "        pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "        pred_masks = pred_masks.astype(np.uint8)\n",
    "        for img_id in range(len(pred_masks)):\n",
    "            for j in range(4):\n",
    "                pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=100)\n",
    "        \n",
    "        # clean predicted masks w/o defects\n",
    "        pred_masks[cls_pred == 4] = 0\n",
    "                \n",
    "        batch_dice = dice_channel_torch(pred_masks, segm_gt.numpy())\n",
    "        dices.append(batch_dice)\n",
    "print(np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54116940898e41cc9324fa58119c1297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9767752887125256\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "cls_th = 0.5\n",
    "segm_th = 0.5\n",
    "\n",
    "dices = []\n",
    "cls_preds = []\n",
    "with torch.no_grad():\n",
    "    for cls_batch, segm_batch in tqdm(zip(cls_dl, segm_dl), total=len(cls_dl)):\n",
    "        cls_features, cls_gt = cls_batch['features'], cls_batch['targets']\n",
    "        cls_features = cls_features.to(device)\n",
    "        cls_logits = cls_model(cls_features).detach().cpu()\n",
    "        cls_probs = torch.softmax(cls_logits, 1).numpy()\n",
    "        cls_pred = cls_probs.argmax(axis=1) # (cls_probs > cls_th).astype(int)\n",
    "        cls_preds.append(cls_pred)\n",
    "        \n",
    "        segm_features, segm_gt = segm_batch\n",
    "        segm_features = segm_features.to(device)\n",
    "        segm_logits = segm_model(segm_features).detach().cpu()\n",
    "        pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "        pred_masks = pred_masks.astype(np.uint8)\n",
    "        for img_id in range(len(pred_masks)):\n",
    "            for j in range(4):\n",
    "                if cls_pred[img_id] == j:\n",
    "                    pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=200)\n",
    "                else:\n",
    "                    pred_masks[img_id, j] = 0\n",
    "        \n",
    "        # clean predicted masks w/o defects\n",
    "        pred_masks[cls_pred == 4] = 0\n",
    "                \n",
    "        batch_dice = dice_channel_torch(pred_masks, segm_gt.numpy())\n",
    "        dices.append(batch_dice)\n",
    "print(np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9774952063689157\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "cls_th = 0.5\n",
    "segm_th = 0.5\n",
    "\n",
    "dices = []\n",
    "cls_preds = []\n",
    "with torch.no_grad():\n",
    "    for cls_batch, segm_batch in tqdm(zip(cls_dl, segm_dl), total=len(cls_dl)):\n",
    "        cls_features, cls_gt = cls_batch['features'], cls_batch['targets']\n",
    "        cls_features = cls_features.to(device)\n",
    "        cls_logits = cls_model(cls_features).detach().cpu()\n",
    "        cls_probs = torch.softmax(cls_logits, 1).numpy()\n",
    "        cls_pred = cls_probs.argmax(axis=1) # (cls_probs > cls_th).astype(int)\n",
    "        cls_preds.append(cls_pred)\n",
    "        \n",
    "        segm_features, segm_gt = segm_batch\n",
    "        segm_features = segm_features.to(device)\n",
    "        segm_logits = segm_model(segm_features).detach().cpu()\n",
    "        pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "        pred_masks = pred_masks.astype(np.uint8)\n",
    "        for img_id in range(len(pred_masks)):\n",
    "            for j in range(4):\n",
    "                pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=200)\n",
    "        \n",
    "        # clean predicted masks w/o defects\n",
    "        pred_masks[cls_pred == 4] = 0\n",
    "                \n",
    "        batch_dice = dice_channel_torch(pred_masks, segm_gt.numpy())\n",
    "        dices.append(batch_dice)\n",
    "print(np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3352b3eeb08e4f79bf58dec4797de9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9776792745706833\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "cls_th = 0.5\n",
    "segm_th = 0.5\n",
    "\n",
    "dices = []\n",
    "cls_preds = []\n",
    "with torch.no_grad():\n",
    "    for cls_batch, segm_batch in tqdm(zip(cls_dl, segm_dl), total=len(cls_dl)):\n",
    "        cls_features, cls_gt = cls_batch['features'], cls_batch['targets']\n",
    "        cls_features = cls_features.to(device)\n",
    "        cls_logits = cls_model(cls_features).detach().cpu()\n",
    "        cls_probs = torch.softmax(cls_logits, 1).numpy()\n",
    "        cls_pred = cls_probs.argmax(axis=1) # (cls_probs > cls_th).astype(int)\n",
    "        cls_preds.append(cls_pred)\n",
    "        \n",
    "        segm_features, segm_gt = segm_batch\n",
    "        segm_features = segm_features.to(device)\n",
    "        segm_logits = segm_model(segm_features).detach().cpu()\n",
    "        pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "        pred_masks = pred_masks.astype(np.uint8)\n",
    "        for img_id in range(len(pred_masks)):\n",
    "            for j in range(4):\n",
    "                pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=100)\n",
    "        \n",
    "        # clean predicted masks w/o defects\n",
    "        pred_masks[cls_pred == 4] = 0\n",
    "                \n",
    "        batch_dice = dice_channel_torch(pred_masks, segm_gt.numpy())\n",
    "        dices.append(batch_dice)\n",
    "print(np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=92), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.9752024519282599\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "cls_th = 0.6\n",
    "segm_th = 0.5\n",
    "\n",
    "dices = []\n",
    "cls_preds = []\n",
    "with torch.no_grad():\n",
    "    for cls_batch, segm_batch in tqdm(zip(cls_dl, segm_dl), total=len(cls_dl)):\n",
    "        cls_features, cls_gt = cls_batch['features'], cls_batch['targets_one_hot']\n",
    "        cls_features = cls_features.to(device)\n",
    "        cls_logits = cls_model(cls_features).detach().cpu()\n",
    "        cls_probs = torch.softmax(cls_logits, 1)[:, 1].numpy()\n",
    "        cls_pred = (cls_probs > cls_th).astype(int)\n",
    "        cls_preds.append(cls_pred)\n",
    "        \n",
    "        segm_features, segm_gt = segm_batch\n",
    "        segm_features = segm_features.to(device)\n",
    "        segm_logits = segm_model(segm_features).detach().cpu()\n",
    "        pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "        pred_masks = pred_masks.astype(np.uint8)\n",
    "        for img_id in range(len(pred_masks)):\n",
    "            for j in range(4):\n",
    "                pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=200)\n",
    "        \n",
    "        # clean predicted masks w/o defects\n",
    "        pred_masks[cls_pred == 0] = 0\n",
    "                \n",
    "        batch_dice = dice_channel_torch(pred_masks, segm_gt.numpy())\n",
    "        dices.append(batch_dice)\n",
    "print(np.mean(dices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dice(model, dl, th=0.5, device='cuda:0'):\n",
    "    dices = []\n",
    "    with torch.no_grad():\n",
    "        for features, gt in tqdm(dl):\n",
    "            features = features.to(device)\n",
    "            logits = model(features).detach().cpu()\n",
    "            batch_dice = dice_channel_torch(logits, gt, th)\n",
    "            dices.append(batch_dice)\n",
    "    return np.mean(dices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(\n",
    "    TEST_IMAGES,\n",
    "    preprocess_img=preprocessing_fn,\n",
    ")\n",
    "test_dl = BaseDataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = TestClsDataset(TEST_IMAGES, preprocess_img=preprocessing_fn)\n",
    "# test_dl = BaseDataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "segm_model = tta_model_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c381e6949cd147cc90c84dffb0e62624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1801), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "min_area = [600, 600, 1000, 2000]\n",
    "\n",
    "cls_th = 0.5\n",
    "segm_th = 0.5\n",
    "\n",
    "cls_preds = []\n",
    "results = []\n",
    "all_probs = []\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(tqdm(test_dl)):\n",
    "        img_id_str = test_dataset.img_ids[i]\n",
    "        \n",
    "#         cls_features = batch\n",
    "#         cls_features = cls_features.to(device)\n",
    "#         cls_logits = cls_model(cls_features).detach().cpu()\n",
    "#         cls_probs = torch.softmax(cls_logits, 1).numpy()\n",
    "#         cls_pred = cls_probs.argmax(axis=1) # (cls_probs > cls_th).astype(int)\n",
    "#         cls_preds.append(cls_pred)\n",
    "#         all_probs.append(cls_probs)\n",
    "        \n",
    "        segm_features = batch\n",
    "        segm_features = segm_features.to(device)\n",
    "        segm_logits = segm_model(segm_features).detach().cpu()\n",
    "        pred_masks = (torch.sigmoid(segm_logits) > segm_th).numpy()\n",
    "        pred_masks = pred_masks.astype(np.uint8)\n",
    "        for img_id in range(len(pred_masks)):\n",
    "            for j in range(4):\n",
    "                if pred_masks[img_id, j].sum() < min_area[j]:\n",
    "                    pred_masks[img_id, j] = np.zeros(\n",
    "                        pred_masks[img_id, j].shape, \n",
    "                        dtype=pred_masks[img_id, j].dtype\n",
    "                    )\n",
    "                pred_masks[img_id, j] = remove_small_one(pred_masks[img_id, j], min_size=100)\n",
    "        \n",
    "        # clean predicted masks w/o defects\n",
    "#         pred_masks[cls_pred == 4] = 0\n",
    "        pred_masks = pred_masks.squeeze()\n",
    "        for ch_id, ch_mask in enumerate(pred_masks):\n",
    "            results.append({\n",
    "                'ImageId_ClassId': f'{img_id_str}_{ch_id + 1}',\n",
    "                'EncodedPixels': mask2rle(ch_mask)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(list(zip(test_dataset.img_ids, all_probs)), open('id2probs.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame(results).set_index('ImageId_ClassId')\n",
    "submit_df.to_csv('submits/super-ensemble-all.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_empty_ids = pickle.load(open('/home/denilv/Downloads/Telegram Desktop/non_emplty_image.pkl', 'rb'))\n",
    "submit_df.loc[submit_df.index.difference(not_empty_ids), 'EncodedPixels'] = ''\n",
    "submit_df.to_csv('submits/super-ensemble-all-wo-empty.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_ids = list(pickle.load(open('/home/denilv/Downloads/Telegram Desktop/empty_ids.pkl', 'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = []\n",
    "for i in empty_ids:\n",
    "    for j in range(1, 5):\n",
    "        aaa.append(f'{i}_{j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df.loc[aaa, 'EncodedPixels'] = ''\n",
    "submit_df.to_csv('submits/super-ensemble-all-wo-empty2.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('submits/23102019-0112.csv', index_col='ImageId_ClassId').fillna('')\n",
    "\n",
    "# not_empty_ids = pickle.load(open('/home/denilv/Downloads/Telegram Desktop/non_emplty_image.pkl', 'rb'))\n",
    "\n",
    "# df.loc[df.index.difference(not_empty_ids), 'EncodedPixels'] = ''\n",
    "\n",
    "# df.to_csv('submits/23102019-0210.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
